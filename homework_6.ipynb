{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6. Классификация новостей\n",
    "\n",
    "### Данные\n",
    "Данные в [архиве](https://drive.google.com/file/d/15o7fdxTgndoy6K-e7g8g1M2-bOOwqZPl/view?usp=sharing). В нём два файла:\n",
    "- `news_train.txt` тестовое множество\n",
    "- `news_test.txt` тренировочное множество\n",
    "\n",
    "С некоторых новостных сайтов были загружены тексты новостей за период  несколько лет, причем каждая новость принаделжит к какой-то рубрике: `science`, `style`, `culture`, `life`, `economics`, `business`, `travel`, `forces`, `media`, `sport`.\n",
    "\n",
    "В каждой строке файла содержится метка рубрики, заголовок новостной статьи и сам текст статьи, например:\n",
    "\n",
    ">    **sport**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею разгромила чехов**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею крупно об...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.1 \n",
    "\n",
    "Обработать данные, получив для каждого текста набор токенов\n",
    "Обработать токены с помощью (один вариант из трех):\n",
    "\n",
    "- pymorphy2\n",
    "- русского [snowball стеммера](https://www.nltk.org/howto/stem.html)\n",
    "- [SentencePiece](https://github.com/google/sentencepiece) или [Huggingface Tokenizers](https://github.com/huggingface/tokenizers)\n",
    "    \n",
    "    \n",
    "## Задание 6.2\n",
    "\n",
    "Обучить word embeddings (fastText, word2vec, gloVe) на тренировочных данных. Можно использовать [gensim](https://radimrehurek.com/gensim/models/word2vec.html) . Продемонстрировать семантические ассоциации. \n",
    "\n",
    "## Задание 6.3\n",
    "\n",
    "Реализовать алгоритм классификации документа по категориям, посчитать точноть на тестовых данных, подобрать гиперпараметры. Метод векторизации выбрать произвольно - можно использовать $tf-idf$ с понижением размерности (см. scikit-learn), можно использовать обученные на предыдущем шаге векторные представления, можно использовать [предобученные модели](https://rusvectores.org/ru/models/). Имейте ввиду, что простое \"усреднение\" токенов в тексте скорее всего не даст положительных результатов. Нужно реализовать два алгоритмов из трех:\n",
    "- SVM\n",
    "- наивный байесовский классификатор\n",
    "- логистическая регрессия\n",
    "    \n",
    "\n",
    "## Задание 6.4* \n",
    "\n",
    "Реализуйте классификацию с помощью нейросетевых моделей. Например [RuBERT](http://docs.deeppavlov.ai/en/master/features/models/bert.html) или [ELMo](https://rusvectores.org/ru/models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_csv(\"news_train.txt\",sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>Овечкин пожертвовал детской хоккейной школе ав...</td>\n",
       "      <td>Нападающий «Вашингтон Кэпиталз» Александр Овеч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>Рекордно дорогую статую майя признали подделкой</td>\n",
       "      <td>Власти Мексики объявили подделкой статую майя,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>Samsung представила флагман в защищенном корпусе</td>\n",
       "      <td>Южнокорейская Samsung анонсировала защищенную ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>С футболиста «Спартака» сняли четырехматчевую ...</td>\n",
       "      <td>Контрольно-дисциплинарный комитет (КДК) РФС сн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>Hopes &amp; Fears объединится с The Village</td>\n",
       "      <td>Интернет-издание Hopes &amp; Fears объявило о свое...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>life</td>\n",
       "      <td>Составлен рейтинг лучших европейских пляжей 20...</td>\n",
       "      <td>Опубликован рейтинг лучших европейских пляжей ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>media</td>\n",
       "      <td>В «Снобе» объяснили причину смены формата</td>\n",
       "      <td>Генеральный директор «Сноб медиа» Марина Гевор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>economics</td>\n",
       "      <td>Минфин предложил штрафовать за биткоины на 50 ...</td>\n",
       "      <td>Минфин разработал законопроект, устанавливающи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>life</td>\n",
       "      <td>Мэл Гибсон заплатит бывшей подруге 750 тысяч д...</td>\n",
       "      <td>Актер и режиссер Мэл Гибсон выплатит своей быв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>media</td>\n",
       "      <td>Еще на двух линиях московского метро заработал...</td>\n",
       "      <td>На Серпуховско-Тимирязевской и Бутовской линия...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                                                  1  \\\n",
       "0          sport  Овечкин пожертвовал детской хоккейной школе ав...   \n",
       "1        culture    Рекордно дорогую статую майя признали подделкой   \n",
       "2        science   Samsung представила флагман в защищенном корпусе   \n",
       "3          sport  С футболиста «Спартака» сняли четырехматчевую ...   \n",
       "4          media            Hopes & Fears объединится с The Village   \n",
       "...          ...                                                ...   \n",
       "14995       life  Составлен рейтинг лучших европейских пляжей 20...   \n",
       "14996      media          В «Снобе» объяснили причину смены формата   \n",
       "14997  economics  Минфин предложил штрафовать за биткоины на 50 ...   \n",
       "14998       life  Мэл Гибсон заплатит бывшей подруге 750 тысяч д...   \n",
       "14999      media  Еще на двух линиях московского метро заработал...   \n",
       "\n",
       "                                                       2  \n",
       "0      Нападающий «Вашингтон Кэпиталз» Александр Овеч...  \n",
       "1      Власти Мексики объявили подделкой статую майя,...  \n",
       "2      Южнокорейская Samsung анонсировала защищенную ...  \n",
       "3      Контрольно-дисциплинарный комитет (КДК) РФС сн...  \n",
       "4      Интернет-издание Hopes & Fears объявило о свое...  \n",
       "...                                                  ...  \n",
       "14995  Опубликован рейтинг лучших европейских пляжей ...  \n",
       "14996  Генеральный директор «Сноб медиа» Марина Гевор...  \n",
       "14997  Минфин разработал законопроект, устанавливающи...  \n",
       "14998  Актер и режиссер Мэл Гибсон выплатит своей быв...  \n",
       "14999  На Серпуховско-Тимирязевской и Бутовской линия...  \n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка текста и его токенизация с использованием Byte-Pair Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import re\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "train_df[2] = train_df[2].map(preprocess_string)\n",
    "tokenizer.train_from_iterator(train_df[2], trainer=trainer)\n",
    "\n",
    "def preprocess_string(string):\n",
    "    prep_str = string.lower()\n",
    "    prep_str = re.sub(r'[\\d\\.[\\]«»,\"\\'%-?:—!;\\(\\)*]', ' ', prep_str)\n",
    "    prep_str = re.sub(r'\\s{2,}', ' ', prep_str) \n",
    "    return prep_str\n",
    "\n",
    "def get_encoded1(text):\n",
    "        return ' '.join(tokenizer.encode(text).tokens)\n",
    "    \n",
    "def get_encoded2(text):\n",
    "    \n",
    "    return tokenizer.encode(text).tokens\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df[2] = df[2].map(preprocess_string)\n",
    "    df = df.rename(columns={0:'label',1:'title',2:'text'})\n",
    "    df['merged_text_tokens'] = df['text'].map(get_encoded1)\n",
    "    df['text_tokens'] = df['text'].map(get_encoded2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>merged_text_tokens</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>Овечкин пожертвовал детской хоккейной школе ав...</td>\n",
       "      <td>нападающий вашингтон кэпиталз александр овечки...</td>\n",
       "      <td>нападающий вашингтон кэпита лз александр овечк...</td>\n",
       "      <td>[нападающий, вашингтон, кэпита, лз, александр,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>Рекордно дорогую статую майя признали подделкой</td>\n",
       "      <td>власти мексики объявили подделкой статую майя ...</td>\n",
       "      <td>власти мексики объявили поддел кой стату ю май...</td>\n",
       "      <td>[власти, мексики, объявили, поддел, кой, стату...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>Samsung представила флагман в защищенном корпусе</td>\n",
       "      <td>южнокорейская samsung анонсировала защищенную ...</td>\n",
       "      <td>южнокорейская samsung анонсировала защищен ную...</td>\n",
       "      <td>[южнокорейская, samsung, анонсировала, защищен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>С футболиста «Спартака» сняли четырехматчевую ...</td>\n",
       "      <td>контрольно дисциплинарный комитет кдк рфс снял...</td>\n",
       "      <td>контрольно дисциплинарный комитет кдк рфс снял...</td>\n",
       "      <td>[контрольно, дисциплинарный, комитет, кдк, рфс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>Hopes &amp; Fears объединится с The Village</td>\n",
       "      <td>интернет издание hopes fears объявило о своем ...</td>\n",
       "      <td>интернет издание hop es fe ars объявило о свое...</td>\n",
       "      <td>[интернет, издание, hop, es, fe, ars, объявило...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>life</td>\n",
       "      <td>Составлен рейтинг лучших европейских пляжей 20...</td>\n",
       "      <td>опубликован рейтинг лучших европейских пляжей ...</td>\n",
       "      <td>опубликован рейтинг лучших европейских пля жей...</td>\n",
       "      <td>[опубликован, рейтинг, лучших, европейских, пл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>media</td>\n",
       "      <td>В «Снобе» объяснили причину смены формата</td>\n",
       "      <td>генеральный директор сноб медиа марина геворкя...</td>\n",
       "      <td>генеральный директор сноб медиа марина ге во р...</td>\n",
       "      <td>[генеральный, директор, сноб, медиа, марина, г...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>economics</td>\n",
       "      <td>Минфин предложил штрафовать за биткоины на 50 ...</td>\n",
       "      <td>минфин разработал законопроект устанавливающий...</td>\n",
       "      <td>минфин разработал законопроект устанавли вающи...</td>\n",
       "      <td>[минфин, разработал, законопроект, устанавли, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>life</td>\n",
       "      <td>Мэл Гибсон заплатит бывшей подруге 750 тысяч д...</td>\n",
       "      <td>актер и режиссер мэл гибсон выплатит своей быв...</td>\n",
       "      <td>актер и режиссер мэ л гиб сон выплатит своей б...</td>\n",
       "      <td>[актер, и, режиссер, мэ, л, гиб, сон, выплатит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>media</td>\n",
       "      <td>Еще на двух линиях московского метро заработал...</td>\n",
       "      <td>на серпуховско тимирязевской и бутовской линия...</td>\n",
       "      <td>на сер пу хов ско ти ми ря зев ской и бу тов с...</td>\n",
       "      <td>[на, сер, пу, хов, ско, ти, ми, ря, зев, ской,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                              title  \\\n",
       "0          sport  Овечкин пожертвовал детской хоккейной школе ав...   \n",
       "1        culture    Рекордно дорогую статую майя признали подделкой   \n",
       "2        science   Samsung представила флагман в защищенном корпусе   \n",
       "3          sport  С футболиста «Спартака» сняли четырехматчевую ...   \n",
       "4          media            Hopes & Fears объединится с The Village   \n",
       "...          ...                                                ...   \n",
       "14995       life  Составлен рейтинг лучших европейских пляжей 20...   \n",
       "14996      media          В «Снобе» объяснили причину смены формата   \n",
       "14997  economics  Минфин предложил штрафовать за биткоины на 50 ...   \n",
       "14998       life  Мэл Гибсон заплатит бывшей подруге 750 тысяч д...   \n",
       "14999      media  Еще на двух линиях московского метро заработал...   \n",
       "\n",
       "                                                    text  \\\n",
       "0      нападающий вашингтон кэпиталз александр овечки...   \n",
       "1      власти мексики объявили подделкой статую майя ...   \n",
       "2      южнокорейская samsung анонсировала защищенную ...   \n",
       "3      контрольно дисциплинарный комитет кдк рфс снял...   \n",
       "4      интернет издание hopes fears объявило о своем ...   \n",
       "...                                                  ...   \n",
       "14995  опубликован рейтинг лучших европейских пляжей ...   \n",
       "14996  генеральный директор сноб медиа марина геворкя...   \n",
       "14997  минфин разработал законопроект устанавливающий...   \n",
       "14998  актер и режиссер мэл гибсон выплатит своей быв...   \n",
       "14999  на серпуховско тимирязевской и бутовской линия...   \n",
       "\n",
       "                                      merged_text_tokens  \\\n",
       "0      нападающий вашингтон кэпита лз александр овечк...   \n",
       "1      власти мексики объявили поддел кой стату ю май...   \n",
       "2      южнокорейская samsung анонсировала защищен ную...   \n",
       "3      контрольно дисциплинарный комитет кдк рфс снял...   \n",
       "4      интернет издание hop es fe ars объявило о свое...   \n",
       "...                                                  ...   \n",
       "14995  опубликован рейтинг лучших европейских пля жей...   \n",
       "14996  генеральный директор сноб медиа марина ге во р...   \n",
       "14997  минфин разработал законопроект устанавли вающи...   \n",
       "14998  актер и режиссер мэ л гиб сон выплатит своей б...   \n",
       "14999  на сер пу хов ско ти ми ря зев ской и бу тов с...   \n",
       "\n",
       "                                             text_tokens  \n",
       "0      [нападающий, вашингтон, кэпита, лз, александр,...  \n",
       "1      [власти, мексики, объявили, поддел, кой, стату...  \n",
       "2      [южнокорейская, samsung, анонсировала, защищен...  \n",
       "3      [контрольно, дисциплинарный, комитет, кдк, рфс...  \n",
       "4      [интернет, издание, hop, es, fe, ars, объявило...  \n",
       "...                                                  ...  \n",
       "14995  [опубликован, рейтинг, лучших, европейских, пл...  \n",
       "14996  [генеральный, директор, сноб, медиа, марина, г...  \n",
       "14997  [минфин, разработал, законопроект, устанавли, ...  \n",
       "14998  [актер, и, режиссер, мэ, л, гиб, сон, выплатит...  \n",
       "14999  [на, сер, пу, хов, ско, ти, ми, ря, зев, ской,...  \n",
       "\n",
       "[15000 rows x 5 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['нападающий',\n",
       " 'вашингтон',\n",
       " 'кэпита',\n",
       " 'лз',\n",
       " 'александр',\n",
       " 'овечкин',\n",
       " 'передал',\n",
       " 'детской',\n",
       " 'хоккейной',\n",
       " 'школе',\n",
       " 'автомобиль',\n",
       " 'полученный',\n",
       " 'им',\n",
       " 'после',\n",
       " 'окончания',\n",
       " 'матча',\n",
       " 'всех',\n",
       " 'звезд',\n",
       " 'национальной',\n",
       " 'хоккейной',\n",
       " 'лиги',\n",
       " 'нхл',\n",
       " 'об',\n",
       " 'этом',\n",
       " 'сообщается',\n",
       " 'на',\n",
       " 'официальном',\n",
       " 'сайте',\n",
       " 'лиги',\n",
       " 'автомобиль',\n",
       " 'hon',\n",
       " 'da',\n",
       " 'ac',\n",
       " 'cor',\n",
       " 'd',\n",
       " 'был',\n",
       " 'пода',\n",
       " 'рен',\n",
       " 'хоккеи',\n",
       " 'сту',\n",
       " 'по',\n",
       " 'решению',\n",
       " 'спонсоров',\n",
       " 'мероприятия',\n",
       " 'игрок',\n",
       " 'нхл',\n",
       " 'пожертво',\n",
       " 'вал',\n",
       " 'машину',\n",
       " 'спортивной',\n",
       " 'школе',\n",
       " 'no',\n",
       " 'va',\n",
       " 'c',\n",
       " 'ool',\n",
       " 'cats',\n",
       " 'spe',\n",
       " 'cial',\n",
       " 'ho',\n",
       " 'ck',\n",
       " 'ey',\n",
       " 'inc',\n",
       " 'которая',\n",
       " 'расположена',\n",
       " 'в',\n",
       " 'штате',\n",
       " 'вирджи',\n",
       " 'ния',\n",
       " 'овечкин',\n",
       " 'общается',\n",
       " 'с',\n",
       " 'летней',\n",
       " 'дево',\n",
       " 'чкой',\n",
       " 'ан',\n",
       " 'ной',\n",
       " 'ш',\n",
       " 'об',\n",
       " 'с',\n",
       " 'син',\n",
       " 'дро',\n",
       " 'мом',\n",
       " 'да',\n",
       " 'уна',\n",
       " 'которая',\n",
       " 'занимается',\n",
       " 'в',\n",
       " 'этой',\n",
       " 'школе',\n",
       " 'и',\n",
       " 'является',\n",
       " 'поклон',\n",
       " 'ницей',\n",
       " 'спортсмена',\n",
       " 'в',\n",
       " 'сентябре',\n",
       " 'форвард',\n",
       " 'по',\n",
       " 'обе',\n",
       " 'дал',\n",
       " 'вместе',\n",
       " 'с',\n",
       " 'ю',\n",
       " 'ной',\n",
       " 'хоккеист',\n",
       " 'кой',\n",
       " 'в',\n",
       " 'японском',\n",
       " 'ресторане',\n",
       " 'матч',\n",
       " 'всех',\n",
       " 'звезд',\n",
       " 'нхл',\n",
       " 'в',\n",
       " 'колам',\n",
       " 'бу',\n",
       " 'се',\n",
       " 'штат',\n",
       " 'огайо',\n",
       " 'завершился',\n",
       " 'победой',\n",
       " 'команды',\n",
       " 'джона',\n",
       " 'тана',\n",
       " 'тэй',\n",
       " 'вза',\n",
       " 'над',\n",
       " 'командой',\n",
       " 'ника',\n",
       " 'фо',\n",
       " 'лин',\n",
       " 'ьо',\n",
       " 'со',\n",
       " 'счетом',\n",
       " 'овечкин',\n",
       " 'выступал',\n",
       " 'за',\n",
       " 'проигра',\n",
       " 'вший',\n",
       " 'коллектив',\n",
       " 'россиянин',\n",
       " 'отметился',\n",
       " 'тремя',\n",
       " 'результативными',\n",
       " 'передача',\n",
       " 'ми']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(train_df['text'][0]).tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение Word2Vec на полученных токенах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=train_df['text_tokens'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2713456 ,  0.75224817,  0.59428364, -0.6661041 ,  0.08521448,\n",
       "       -1.1017848 , -0.12180103,  0.2086696 , -0.36816072, -1.0579935 ,\n",
       "        0.14635268, -3.5296223 , -0.90736055, -0.03458572, -0.5147749 ,\n",
       "       -1.3134733 ,  0.74391466, -0.17755744, -1.7102655 ,  0.6313617 ,\n",
       "       -0.42276067,  0.09915036,  0.6468228 , -0.8001307 , -1.2569528 ,\n",
       "       -0.04318319, -1.482901  , -0.20788544, -1.31753   , -0.62850875,\n",
       "       -0.05660382, -0.31488466,  1.109137  , -0.05896315, -1.2651093 ,\n",
       "        2.0284936 , -0.15981647,  0.08660134, -0.5327433 ,  2.0972307 ,\n",
       "        0.3127952 , -0.22878267,  1.1684858 ,  1.2634224 , -0.30763727,\n",
       "        1.2356262 ,  1.2154336 , -1.6669316 , -1.2354722 , -1.0382768 ,\n",
       "       -0.9579463 ,  0.52561754,  0.12588295,  0.71330774, -0.2549415 ,\n",
       "       -1.0028055 ,  2.3972318 , -1.2096295 ,  0.23734261,  0.30219495,\n",
       "        0.04685164, -2.617919  , -0.04401742, -0.04873738,  0.47371677,\n",
       "       -0.48354405, -0.5552493 ,  1.6642933 , -1.494386  ,  0.261548  ,\n",
       "       -0.76125944,  0.9479632 ,  1.3409256 ,  0.730099  ,  0.6879864 ,\n",
       "        0.02551544,  0.31874266,  1.1781602 , -1.0906522 ,  0.30966675,\n",
       "       -1.1497933 ,  0.6472814 , -0.7923588 , -1.6849226 , -0.7556649 ,\n",
       "       -0.21810961,  0.28940427,  0.22704366, -0.10337703,  1.4200469 ,\n",
       "        0.26439264, -0.36483836, -0.88438034, -0.53329676, -1.7095951 ,\n",
       "        0.3554286 , -0.5580544 ,  0.18325537,  0.34580055,  1.3131773 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.wv['интернет']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск близких по смыслу токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('средства', 0.8091498017311096),\n",
       " ('платить', 0.7652372121810913),\n",
       " ('банки', 0.7526605129241943),\n",
       " ('налоги', 0.7471795082092285),\n",
       " ('свои', 0.7327820658683777),\n",
       " ('кредиты', 0.7322941422462463),\n",
       " ('вырученные', 0.7310887575149536),\n",
       " ('штрафы', 0.7225716710090637),\n",
       " ('денег', 0.7202186584472656),\n",
       " ('финансовые', 0.7194145321846008)]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(tokenizer.encode('деньги').tokens, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('соцсети', 0.7878230810165405),\n",
       " ('google', 0.7545526027679443),\n",
       " ('сервис', 0.7533242702484131),\n",
       " ('сети', 0.7499057054519653),\n",
       " ('сервиса', 0.7421565651893616),\n",
       " ('яндекс', 0.7381110787391663),\n",
       " ('онлайн', 0.7365279197692871),\n",
       " ('микроблогов', 0.7287245392799377),\n",
       " ('ebay', 0.7193353772163391),\n",
       " ('yahoo', 0.7118775248527527)]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(tokenizer.encode('интернет').tokens, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем тестовые данные и предобрабатываем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"news_test.txt\",sep=\"\\t\", header=None)\n",
    "test_df = preprocess_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>merged_text_tokens</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culture</td>\n",
       "      <td>Жительница Ямала победила в первом песенном ко...</td>\n",
       "      <td>жительница ямало ненецкого автономного округа ...</td>\n",
       "      <td>жительница я мало нен ец кого автоном ного окр...</td>\n",
       "      <td>[жительница, я, мало, нен, ец, кого, автоном, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>media</td>\n",
       "      <td>Почти половина Twitter-пользователей никогда н...</td>\n",
       "      <td>около процентов из всех зарегистрированных в t...</td>\n",
       "      <td>около процентов из всех зарегистрированных в t...</td>\n",
       "      <td>[около, процентов, из, всех, зарегистрированны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>media</td>\n",
       "      <td>Билайн начал рекламу роуминга под песенку \"Тро...</td>\n",
       "      <td>в новой рекламной кампании мобильного оператор...</td>\n",
       "      <td>в новой рекламной кампании мобильного оператор...</td>\n",
       "      <td>[в, новой, рекламной, кампании, мобильного, оп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Saipem потеряла 1,2 миллиарда евро из-за отмен...</td>\n",
       "      <td>дочерняя структура итальянского нефтегазового ...</td>\n",
       "      <td>дочерняя структура итальянского нефтегазо вого...</td>\n",
       "      <td>[дочерняя, структура, итальянского, нефтегазо,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>culture</td>\n",
       "      <td>Вин Дизель назвал «Форсаж 7» достойным «Оскара»</td>\n",
       "      <td>актер вин дизель заявил что боевик форсаж в ко...</td>\n",
       "      <td>актер вин дизель заявил что боевик форсаж в ко...</td>\n",
       "      <td>[актер, вин, дизель, заявил, что, боевик, форс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>science</td>\n",
       "      <td>Причиной \"влажного\" климата Титана оказались м...</td>\n",
       "      <td>ученые прояснили причины влажного климата тита...</td>\n",
       "      <td>ученые проясни ли причины вла жного климата ти...</td>\n",
       "      <td>[ученые, проясни, ли, причины, вла, жного, кли...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>life</td>\n",
       "      <td>Британка нашла геккона в пакете с брокколи</td>\n",
       "      <td>жительница великобритании нашла геккона в паке...</td>\n",
       "      <td>жительница великобритании нашла ге к кона в па...</td>\n",
       "      <td>[жительница, великобритании, нашла, ге, к, кон...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>business</td>\n",
       "      <td>Владелец «Мечела» предложил закрыть в России в...</td>\n",
       "      <td>совладелец горно металлургического холдинга ме...</td>\n",
       "      <td>совладелец горно металлурги ческого холдинга м...</td>\n",
       "      <td>[совладелец, горно, металлурги, ческого, холди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>science</td>\n",
       "      <td>Nokia выпустит ОС для бюджетных смартфонов</td>\n",
       "      <td>компания nokia разрабатывает операционную сист...</td>\n",
       "      <td>компания nokia разрабатывает операционную сист...</td>\n",
       "      <td>[компания, nokia, разрабатывает, операционную,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>life</td>\n",
       "      <td>В Калифорнии появилось радио для собак и кошек</td>\n",
       "      <td>в лос анджелесе вещает радиостанция для домашн...</td>\n",
       "      <td>в лос анджелесе вещает радиостанция для домашн...</td>\n",
       "      <td>[в, лос, анджелесе, вещает, радиостанция, для,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                              title  \\\n",
       "0      culture  Жительница Ямала победила в первом песенном ко...   \n",
       "1        media  Почти половина Twitter-пользователей никогда н...   \n",
       "2        media  Билайн начал рекламу роуминга под песенку \"Тро...   \n",
       "3     business  Saipem потеряла 1,2 миллиарда евро из-за отмен...   \n",
       "4      culture    Вин Дизель назвал «Форсаж 7» достойным «Оскара»   \n",
       "...        ...                                                ...   \n",
       "2995   science  Причиной \"влажного\" климата Титана оказались м...   \n",
       "2996      life         Британка нашла геккона в пакете с брокколи   \n",
       "2997  business  Владелец «Мечела» предложил закрыть в России в...   \n",
       "2998   science         Nokia выпустит ОС для бюджетных смартфонов   \n",
       "2999      life     В Калифорнии появилось радио для собак и кошек   \n",
       "\n",
       "                                                   text  \\\n",
       "0     жительница ямало ненецкого автономного округа ...   \n",
       "1     около процентов из всех зарегистрированных в t...   \n",
       "2     в новой рекламной кампании мобильного оператор...   \n",
       "3     дочерняя структура итальянского нефтегазового ...   \n",
       "4     актер вин дизель заявил что боевик форсаж в ко...   \n",
       "...                                                 ...   \n",
       "2995  ученые прояснили причины влажного климата тита...   \n",
       "2996  жительница великобритании нашла геккона в паке...   \n",
       "2997  совладелец горно металлургического холдинга ме...   \n",
       "2998  компания nokia разрабатывает операционную сист...   \n",
       "2999  в лос анджелесе вещает радиостанция для домашн...   \n",
       "\n",
       "                                     merged_text_tokens  \\\n",
       "0     жительница я мало нен ец кого автоном ного окр...   \n",
       "1     около процентов из всех зарегистрированных в t...   \n",
       "2     в новой рекламной кампании мобильного оператор...   \n",
       "3     дочерняя структура итальянского нефтегазо вого...   \n",
       "4     актер вин дизель заявил что боевик форсаж в ко...   \n",
       "...                                                 ...   \n",
       "2995  ученые проясни ли причины вла жного климата ти...   \n",
       "2996  жительница великобритании нашла ге к кона в па...   \n",
       "2997  совладелец горно металлурги ческого холдинга м...   \n",
       "2998  компания nokia разрабатывает операционную сист...   \n",
       "2999  в лос анджелесе вещает радиостанция для домашн...   \n",
       "\n",
       "                                            text_tokens  \n",
       "0     [жительница, я, мало, нен, ец, кого, автоном, ...  \n",
       "1     [около, процентов, из, всех, зарегистрированны...  \n",
       "2     [в, новой, рекламной, кампании, мобильного, оп...  \n",
       "3     [дочерняя, структура, итальянского, нефтегазо,...  \n",
       "4     [актер, вин, дизель, заявил, что, боевик, форс...  \n",
       "...                                                 ...  \n",
       "2995  [ученые, проясни, ли, причины, вла, жного, кли...  \n",
       "2996  [жительница, великобритании, нашла, ге, к, кон...  \n",
       "2997  [совладелец, горно, металлурги, ческого, холди...  \n",
       "2998  [компания, nokia, разрабатывает, операционную,...  \n",
       "2999  [в, лос, анджелесе, вещает, радиостанция, для,...  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация алгоритмом логистической регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('lr_estimator',\n",
       "                 LogisticRegression(max_iter=1000, random_state=8))])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr_estimator', LogisticRegression(random_state=8,max_iter=1000))])\n",
    "lr_clf.fit(train_df.merged_text_tokens, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.22      0.71      0.34        28\n",
      "     culture       0.93      0.93      0.93       429\n",
      "   economics       0.91      0.83      0.87       465\n",
      "      forces       0.88      0.81      0.85       266\n",
      "        life       0.91      0.80      0.85       471\n",
      "       media       0.86      0.83      0.85       416\n",
      "     science       0.85      0.90      0.87       441\n",
      "       sport       0.96      0.98      0.97       416\n",
      "       style       0.75      0.97      0.85        40\n",
      "      travel       0.48      0.93      0.63        28\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.78      0.87      0.80      3000\n",
      "weighted avg       0.89      0.87      0.88      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_lr = lr_clf.predict(test_df.merged_text_tokens)\n",
    "print(metrics.classification_report(predicted_lr, test_df.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение параметра:  {'lr_estimator__C': 50.0}\n",
      "Лучший результат модели:  0.8702666666666667\n"
     ]
    }
   ],
   "source": [
    "params_lr = {'lr_estimator__C': [50.0, 20.0, 10.0, 5.0, 1.0, 0.5]}\n",
    "grid_lr = GridSearchCV(estimator=lr_clf, param_grid=params_lr)\n",
    "grid_lr.fit(train_df.merged_text_tokens, train_df.label)\n",
    "print(\"Лучшее значение параметра: \", grid_lr.best_params_)\n",
    "print(\"Лучший результат модели: \", grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.47      0.69      0.56        61\n",
      "     culture       0.92      0.92      0.92       425\n",
      "   economics       0.92      0.87      0.89       449\n",
      "      forces       0.88      0.84      0.86       256\n",
      "        life       0.90      0.83      0.87       449\n",
      "       media       0.86      0.86      0.86       402\n",
      "     science       0.87      0.90      0.88       451\n",
      "       sport       0.97      0.98      0.98       420\n",
      "       style       0.87      0.92      0.89        49\n",
      "      travel       0.67      0.95      0.78        38\n",
      "\n",
      "    accuracy                           0.89      3000\n",
      "   macro avg       0.83      0.88      0.85      3000\n",
      "weighted avg       0.89      0.89      0.89      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_grid_lr = grid_lr.predict(test_df.merged_text_tokens)\n",
    "print(metrics.classification_report(predicted_grid_lr, test_df.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация наивной баесовской моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('nb_estimator', MultinomialNB())])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb_estimator', MultinomialNB())])\n",
    "nb_clf.fit(train_df.merged_text_tokens, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.00      0.00      0.00         0\n",
      "     culture       0.92      0.87      0.89       453\n",
      "   economics       0.94      0.73      0.83       546\n",
      "      forces       0.79      0.83      0.81       234\n",
      "        life       0.88      0.79      0.83       464\n",
      "       media       0.83      0.80      0.82       418\n",
      "     science       0.84      0.87      0.85       450\n",
      "       sport       0.98      0.97      0.97       431\n",
      "       style       0.08      1.00      0.14         4\n",
      "      travel       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.63      0.69      0.61      3000\n",
      "weighted avg       0.89      0.83      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_nb = nb_clf.predict(test_df.merged_text_tokens)\n",
    "print(metrics.classification_report(predicted_nb, test_df.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_estimator__alpha': 0.5} 0.8186666666666668\n"
     ]
    }
   ],
   "source": [
    "params_nb = {'nb_estimator__alpha': [0, 0.5, 1.0, 2.0]}\n",
    "grid_nb = GridSearchCV(nb_clf, params_nb)\n",
    "grid_nb.fit(train_df.merged_text_tokens, train_df.label)\n",
    "print(grid_nb.best_params_, grid_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.02      0.50      0.04         4\n",
      "     culture       0.92      0.89      0.90       440\n",
      "   economics       0.93      0.75      0.83       527\n",
      "      forces       0.85      0.77      0.81       270\n",
      "        life       0.88      0.79      0.83       466\n",
      "       media       0.82      0.80      0.81       411\n",
      "     science       0.82      0.88      0.85       430\n",
      "       sport       0.97      0.97      0.97       422\n",
      "       style       0.42      1.00      0.59        22\n",
      "      travel       0.15      1.00      0.26         8\n",
      "\n",
      "    accuracy                           0.84      3000\n",
      "   macro avg       0.68      0.84      0.69      3000\n",
      "weighted avg       0.88      0.84      0.85      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_grid_nb = grid_nb.predict(test_df.merged_text_tokens)\n",
    "print(metrics.classification_report(predicted_grid_nb, test_df.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод опорных векторов без поиска лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('nb_estimator', SVC())])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb_estimator', svm.SVC())])\n",
    "sv_clf.fit(train_df.merged_text_tokens, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.18      0.70      0.28        23\n",
      "     culture       0.92      0.94      0.93       418\n",
      "   economics       0.92      0.82      0.86       476\n",
      "      forces       0.90      0.82      0.86       267\n",
      "        life       0.93      0.80      0.86       485\n",
      "       media       0.86      0.83      0.85       418\n",
      "     science       0.85      0.91      0.88       431\n",
      "       sport       0.96      0.98      0.97       414\n",
      "       style       0.75      0.95      0.84        41\n",
      "      travel       0.48      0.96      0.64        27\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.77      0.87      0.80      3000\n",
      "weighted avg       0.89      0.87      0.88      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_nb = sv_clf.predict(test_df.merged_text_tokens)\n",
    "print(metrics.classification_report(predicted_nb, test_df.label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
